"""
Prometheus Metrics Collection for RAG System

This module provides comprehensive metrics collection for monitoring
the RAG pipeline performance, quality, and operational health.
"""

from prometheus_client import Counter, Histogram, Gauge, Summary
from typing import Optional
import time

# ============================================================================
# Query Metrics
# ============================================================================

query_total = Counter(
    'rag_queries_total',
    'Total number of queries processed',
    ['embedder_type', 'status', 'cache_status']
)

query_duration = Histogram(
    'rag_query_duration_seconds',
    'End-to-end query processing duration',
    ['embedder_type'],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0]
)

query_tokens = Histogram(
    'rag_query_tokens',
    'Token usage per query',
    ['stage', 'type']  # stage: input/output, type: query/generation
)

# ============================================================================
# Retrieval Metrics
# ============================================================================

retrieval_docs = Histogram(
    'rag_retrieval_docs',
    'Number of documents retrieved',
    ['retriever_type', 'stage'],  # stage: initial/reranked
    buckets=[1, 5, 10, 20, 50, 100]
)

retrieval_duration = Histogram(
    'rag_retrieval_duration_seconds',
    'Retrieval operation duration',
    ['retriever_type', 'stage'],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0]
)

retrieval_scores = Histogram(
    'rag_retrieval_scores',
    'Retrieval similarity scores',
    ['retriever_type'],
    buckets=[0.0, 0.2, 0.4, 0.6, 0.7, 0.8, 0.9, 0.95, 1.0]
)

retrieval_quality = Histogram(
    'rag_retrieval_quality_score',
    'Retrieval quality score (composite metric)',
    ['embedder_type'],
    buckets=[0.0, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
)

# ============================================================================
# Generation Metrics
# ============================================================================

generation_duration = Histogram(
    'rag_generation_duration_seconds',
    'LLM generation duration',
    ['model_type'],
    buckets=[0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0]
)

generation_tokens = Histogram(
    'rag_generation_tokens',
    'Tokens generated by LLM',
    ['model_type'],
    buckets=[100, 500, 1000, 2000, 5000, 10000]
)

generation_errors = Counter(
    'rag_generation_errors_total',
    'Generation errors',
    ['error_type', 'model_type']
)

answer_length = Histogram(
    'rag_answer_length',
    'Answer length in characters',
    buckets=[100, 500, 1000, 2000, 5000, 10000]
)

citation_count = Histogram(
    'rag_citation_count',
    'Number of citations per answer',
    buckets=[0, 1, 2, 3, 5, 10, 20]
)

# ============================================================================
# Embedding Metrics
# ============================================================================

embedding_duration = Histogram(
    'rag_embedding_duration_seconds',
    'Embedding generation duration',
    ['embedder_type'],
    buckets=[0.001, 0.01, 0.05, 0.1, 0.5, 1.0]
)

embedding_requests = Counter(
    'rag_embedding_requests_total',
    'Total embedding requests',
    ['embedder_type', 'status']
)

embedder_usage = Counter(
    'rag_embedder_usage_total',
    'Embedder type usage',
    ['embedder_type']
)

# ============================================================================
# Cache Metrics
# ============================================================================

cache_hits = Counter(
    'rag_cache_hits_total',
    'Cache hits',
    ['cache_type']
)

cache_misses = Counter(
    'rag_cache_misses_total',
    'Cache misses',
    ['cache_type']
)

cache_size = Gauge(
    'rag_cache_size',
    'Current cache size in entries',
    ['cache_type']
)

cache_operations = Counter(
    'rag_cache_operations_total',
    'Cache operations',
    ['operation', 'cache_type']  # operation: get/set/evict
)

# ============================================================================
# System Metrics
# ============================================================================

vector_store_size = Gauge(
    'rag_vector_store_size',
    'Total documents in vector store'
)

vector_store_operations = Counter(
    'rag_vector_store_operations_total',
    'Vector store operations',
    ['operation', 'status']  # operation: insert/query/delete
)

elasticsearch_operations = Counter(
    'rag_elasticsearch_operations_total',
    'Elasticsearch operations',
    ['operation', 'status']
)

redis_operations = Counter(
    'rag_redis_operations_total',
    'Redis operations',
    ['operation', 'status']
)

# ============================================================================
# Quality Metrics
# ============================================================================

user_feedback = Counter(
    'rag_user_feedback_total',
    'User feedback ratings',
    ['rating']  # rating: positive/negative/neutral
)

query_complexity = Histogram(
    'rag_query_complexity',
    'Query complexity score',
    buckets=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0]
)

# ============================================================================
# Helper Functions
# ============================================================================

class MetricsCollector:
    """Helper class for collecting metrics with context."""
    
    @staticmethod
    def record_query(
        embedder_type: str,
        status: str,
        cache_hit: bool,
        duration: float,
        retrieved_docs: int,
        answer_length: int,
        citation_count: int
    ):
        """Record query metrics."""
        cache_status = "hit" if cache_hit else "miss"
        query_total.labels(
            embedder_type=embedder_type,
            status=status,
            cache_status=cache_status
        ).inc()
        
        query_duration.labels(embedder_type=embedder_type).observe(duration)
        retrieval_docs.labels(
            retriever_type="hybrid",
            stage="final"
        ).observe(retrieved_docs)
        # Access module-level metric objects via globals() to avoid parameter shadowing
        globals()['answer_length'].observe(answer_length)
        globals()['citation_count'].observe(citation_count)
    
    @staticmethod
    def record_retrieval(
        retriever_type: str,
        stage: str,
        duration: float,
        doc_count: int,
        avg_score: Optional[float] = None
    ):
        """Record retrieval metrics."""
        retrieval_duration.labels(
            retriever_type=retriever_type,
            stage=stage
        ).observe(duration)
        retrieval_docs.labels(
            retriever_type=retriever_type,
            stage=stage
        ).observe(doc_count)
        
        if avg_score is not None:
            retrieval_scores.labels(retriever_type=retriever_type).observe(avg_score)
    
    @staticmethod
    def record_generation(
        model_type: str,
        duration: float,
        tokens: int
    ):
        """Record generation metrics."""
        generation_duration.labels(model_type=model_type).observe(duration)
        generation_tokens.labels(model_type=model_type).observe(tokens)
    
    @staticmethod
    def record_embedding(
        embedder_type: str,
        duration: float,
        status: str = "success"
    ):
        """Record embedding metrics."""
        embedding_duration.labels(embedder_type=embedder_type).observe(duration)
        embedding_requests.labels(
            embedder_type=embedder_type,
            status=status
        ).inc()
        embedder_usage.labels(embedder_type=embedder_type).inc()
    
    @staticmethod
    def record_cache(
        cache_type: str,
        operation: str,
        hit: Optional[bool] = None
    ):
        """Record cache metrics."""
        cache_operations.labels(
            operation=operation,
            cache_type=cache_type
        ).inc()
        
        if hit is not None:
            if hit:
                cache_hits.labels(cache_type=cache_type).inc()
            else:
                cache_misses.labels(cache_type=cache_type).inc()
    
    @staticmethod
    def update_cache_size(cache_type: str, size: int):
        """Update cache size metric."""
        cache_size.labels(cache_type=cache_type).set(size)
    
    @staticmethod
    def update_vector_store_size(size: int):
        """Update vector store size metric."""
        vector_store_size.set(size)
    
    @staticmethod
    def record_error(error_type: str, model_type: str = "unknown"):
        """Record error metric."""
        generation_errors.labels(
            error_type=error_type,
            model_type=model_type
        ).inc()

